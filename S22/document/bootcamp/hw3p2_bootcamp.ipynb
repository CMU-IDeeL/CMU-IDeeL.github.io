{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "hw3p2_bootcamp.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iqxhejj_yxxo"
      },
      "source": [
        "# 1 Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPhXLOOGy23O"
      },
      "source": [
        "## 1.1 Google Drive - Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e15Pr4YZyzx6",
        "outputId": "e59d0f20-7ba4-4b39-d6c3-88cd1c1cfc57"
      },
      "source": [
        "# Google drive setup\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGghymIKyzkY"
      },
      "source": [
        "import json\n",
        "\n",
        "api_token = {\"username\":\"xxxxxxxxx\",\"key\":\"xxxxxxxxx\"}\n",
        "\n",
        "!mkdir .kaggle\n",
        "!mkdir ~/.kaggle\n",
        "\n",
        "with open('/content/.kaggle/kaggle.json', 'w') as file:\n",
        "  json.dump(api_token, file)\n",
        "\n",
        "!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxC5bG9DzCwP"
      },
      "source": [
        "!pip install --upgrade --force-reinstall --no-deps kaggle\n",
        "!kaggle --version"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDAvSWLFzHTy"
      },
      "source": [
        "## 1.2 Kaggle Data Download"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhUzmdN9BMha"
      },
      "source": [
        "# download data\n",
        "!kaggle competitions download -c 11785-fall2021-hw3p2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lxbGtNvzP5x"
      },
      "source": [
        "!mkdir data\n",
        "\n",
        "!unzip -qo './11785-fall2021-hw3p2.zip' -d data "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3v4SIZkWz8xo"
      },
      "source": [
        "!ls data/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWjk6wdDKGM0"
      },
      "source": [
        "## 1.3 Library Installations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCW-7s2CKRE6"
      },
      "source": [
        "Install [ctcdecode](https://github.com/parlance/ctcdecode)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWnh9OW2KFC6"
      },
      "source": [
        "!git clone --recursive https://github.com/parlance/ctcdecode.git\n",
        "!pip install wget\n",
        "%cd ctcdecode\n",
        "!pip install .\n",
        "%cd .."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFq2DZ1JKmx0"
      },
      "source": [
        "Install [levenshtein distance calculation library](https://github.com/ztane/python-Levenshtein) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wV1_xPiKiJV"
      },
      "source": [
        "!pip install python-Levenshtein"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yqlnQRA0DZk"
      },
      "source": [
        "## 1.4 Libraries & Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAHPFFCc0C7b"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import time\n",
        "\n",
        "import Levenshtein\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pdb\n",
        "import gc\n",
        "from tqdm.notebook import trange, tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvSpD3_q0UHH"
      },
      "source": [
        "# Check if cuda is available and set device\n",
        "cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
        "\n",
        "num_workers = 8 if cuda else 0\n",
        "\n",
        "print(\"Cuda = \", str(cuda), \" with num_workers = \", str(num_workers),  \" system version = \", sys.version)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YopAeO_XRhTQ"
      },
      "source": [
        "# 2 Data Loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKo7GEsBa4sR"
      },
      "source": [
        "## 2.1 Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BDZrzzlF5sq"
      },
      "source": [
        "# load training and dev data\n",
        "train_data = np.load('data/HW3P2_Data/train.npy', allow_pickle=True)\n",
        "train_labels = np.load('data/HW3P2_Data/train_labels.npy', allow_pickle=True)\n",
        "\n",
        "dev_data = np.load('data/HW3P2_Data/dev.npy', allow_pickle=True)\n",
        "dev_labels = np.load('data/HW3P2_Data/dev_labels.npy', allow_pickle=True)\n",
        "\n",
        "# load test data\n",
        "test_data = np.load('data/HW3P2_Data/test.npy', allow_pickle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rf89XpGrmYHq"
      },
      "source": [
        "print(f'Train data: {train_data.shape}')\n",
        "print(f'Train labels {train_labels.shape}')\n",
        "\n",
        "print(f'Dev data: {dev_data.shape}')\n",
        "print(f'Dev labels {dev_labels.shape}')\n",
        "\n",
        "print(f'Test data: {test_data.shape}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iLs7aLgbB8Q"
      },
      "source": [
        "## 2.2 Custom Dataset Classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-0Seqh4Cp9F"
      },
      "source": [
        "# Define dataset class\n",
        "class MyDataSet(Dataset):\n",
        "  # load the dataset\n",
        "  def __init__(self, x, y):\n",
        "    self.X = x\n",
        "    self.Y = y\n",
        "\n",
        "  # get number of items/rows in dataset\n",
        "  def __len__(self):\n",
        "    return len(self.Y)\n",
        "\n",
        "  # get row item at some index\n",
        "  def __getitem__(self, index):\n",
        "    x = torch.FloatTensor(self.X[index])\n",
        "    y = torch.LongTensor(self.Y[index])\n",
        "\n",
        "    return x, y\n",
        "\n",
        "  def collate_fn(batch):\n",
        "    # TODO: Pad sequence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYTDtHEGHsWZ"
      },
      "source": [
        "# Define dataset class\n",
        "class TestDataSet(Dataset):\n",
        "  # load the dataset\n",
        "  # TODO: replace x and y with dataset path and load data from here -> more efficient\n",
        "  def __init__(self, x):\n",
        "    self.X = x\n",
        "\n",
        "  # get number of items/rows in dataset\n",
        "  def __len__(self):\n",
        "    return len(self.X) \n",
        "\n",
        "  # get row item at some index\n",
        "  def __getitem__(self, index):\n",
        "    x = torch.FloatTensor(self.X[index])\n",
        "    return x\n",
        "\n",
        "  def collate_fn(batch):\n",
        "    # TODO: Pad X\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4ppavAxbGYv"
      },
      "source": [
        "## 2.3 Data Loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_knptYW7RR73"
      },
      "source": [
        "batch_size = ... # TODO: decide on batch size\n",
        "\n",
        "# training data\n",
        "train = MyDataSet(train_data, train_labels)\n",
        "train_args = .... # TODO: remember to use collate_fn\n",
        "train_loader = DataLoader(train, **train_args)\n",
        "\n",
        "# validation data\n",
        "dev = MyDataSet(dev_data, dev_labels)\n",
        "dev_args = .... # TODO: remember to use collate_fn\n",
        "dev_loader = DataLoader(dev, **dev_args)\n",
        "\n",
        "# test data\n",
        "test = TestDataSet(test_data)\n",
        "test_args = .... # TODO: remember to use collate_fn\n",
        "test_loader = DataLoader(test, **test_args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bt_fIhfDbMMm"
      },
      "source": [
        "# 2 Model Building"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSSX7kU5XBy_"
      },
      "source": [
        "## 2.1 Model Creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-sSvKi9TR_M"
      },
      "source": [
        "# TODO: Create model    \n",
        "class LSTMModel(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "    super(LSTMModel, self).__init__()\n",
        "\n",
        "    \n",
        "  def forward(self, x, lengths): \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_2OrOTObTEy"
      },
      "source": [
        "## 2.2 Model Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4q8xJFgnZT1v"
      },
      "source": [
        "# create model\n",
        "input_size = \n",
        "hidden_size = \n",
        "num_layers = \n",
        "output_size = \n",
        "\n",
        "model = LSTMModel(input_size, hidden_size, num_layers, output_size)\n",
        "model = model.to(device)\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1hBJnqPjxyu"
      },
      "source": [
        "# 4 Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azt5PaudbbmK"
      },
      "source": [
        "## 4.0 Set Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6cbZIpDBWFa"
      },
      "source": [
        "# Hyperparams\n",
        "\n",
        "\n",
        "criterion = nn.CTCLoss()\n",
        "optimizer = \n",
        "\n",
        "# You can add a LR scheduler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWLIH1eNbjtg"
      },
      "source": [
        "## 4.1 Train Epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtUS0ck-aC5-"
      },
      "source": [
        "# Train the model\n",
        "def train_epoch(model, train_loader, criterion, optimizer):\n",
        "  model.train()\n",
        "\n",
        "  avg_loss = 0.0\n",
        "  start = time.time()\n",
        "\n",
        "  # TODO: Add logic here\n",
        "\n",
        "  end = time.time()\n",
        "  avg_loss /= len(train_loader) # average batch loss\n",
        "\n",
        "  print(f'Training loss: {avg_loss} Time: {end - start}')\n",
        "  return avg_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idmvOyiEq63H"
      },
      "source": [
        "## 4.2 CTC Decoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrIW7OENr7fg"
      },
      "source": [
        "import sys\n",
        "sys.path.append(\"data/HW3P2_Data\")\n",
        "\n",
        "from phoneme_list import PHONEME_MAP, PHONEME_LIST"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mby2lwGsX-a"
      },
      "source": [
        "from ctcdecode import CTCBeamDecoder\n",
        "\n",
        "# TODO: Initialize decoder here\n",
        "# In CTCBeamDecoder beam_width=1 (greedy search); beam_width>1 (beam search)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arxNVRFvj0ro"
      },
      "source": [
        "## 4.3 Validate Epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_5ydu7ciNye"
      },
      "source": [
        "# Train the model\n",
        "def validate_model(model, val_loader, criterion):\n",
        "\n",
        "  avg_loss = 0.0\n",
        "  running_dist = 0.0\n",
        "  predictions = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    # model in validation mode \n",
        "    model.eval()\n",
        "\n",
        "    start = time.time()\n",
        "\n",
        "    # TODO: Add logic here (remember to decode output and compute distance)\n",
        "\n",
        "    end = time.time()\n",
        "\n",
        "    print(f'Validation loss: {avg_loss} Levenshtein distance: {running_dist} Time: {end - start}')\n",
        "    return avg_loss, predictions, distances, running_dist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8vCpkiblZbY"
      },
      "source": [
        "## 4.4 Run Epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tjnPWR_MlDNZ"
      },
      "source": [
        "# Define number of epochs\n",
        "epochs = ...\n",
        "\n",
        "best_loss = float('inf')\n",
        "\n",
        "print('Start...')\n",
        "for epoch in range(epochs):\n",
        "  print('Epoch: ', epoch+1)\n",
        "\n",
        "  training_loss = train_epoch(model, train_loader, criterion, optimizer)\n",
        "  val_loss, predictions, distance, running_dist = validate_model(model, dev_loader, criterion)\n",
        "\n",
        "  # save the best model\n",
        "  if val_loss < best_loss:\n",
        "    print('Best loss: {}, epoch: {}'.format(val_loss, epoch + 1))\n",
        "    # TODO: Save model\n",
        "    best_loss = val_loss\n",
        "\n",
        "  print('='*40)\n",
        "print('Done...')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvD2JK1ifND_"
      },
      "source": [
        "# 5 Test Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1MvZuK2b4TO"
      },
      "source": [
        "## 5.1 Make Predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9I9VwH_ppG3b"
      },
      "source": [
        "## 5.2 Save Predictions to csv File"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShgVcbGtiSNQ"
      },
      "source": [
        "## 5.3 Submit Predictions"
      ]
    }
  ]
}