{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bTQ-ExnoiAeY"
   },
   "source": [
    "## TensorBoard for Visualization\n",
    "\n",
    "TensorBoard is a neural network visualization library developed by Google as part of Tensorflow. In the past, people can use TensorBoard in PyTorch via third-party adaptors like tensorboardX. Starting from 1.2.0 (the latest version), **PyTorch officially supports TensorBoard**. We recommend you to use the latest version of PyTorch and use its built-in support of TensorBoard for visualization.\n",
    "\n",
    "This tutorial covers how to use PyTorch's official support of TensorBoard. You can also refer to the [official documentation](https://pytorch.org/docs/stable/tensorboard.html). If you insist on using an older version of PyTorch, try [tensorboardX](https://github.com/lanpa/tensorboardX).\n",
    "\n",
    "Let's take up the same task as defined in Recitation 2. We'll be training a Neural Network to classify if a set of points $(x_1, x_2)$ lie inside a circle of radius $1$ or not. For more details on what the task is, please re-visit Recitation 2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UwK3leNfLxwe"
   },
   "outputs": [],
   "source": [
    "# Install required libraries\n",
    "!pip install torch>=1.2.0 tensorboard future tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_vXkLZjiiAec"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WdKH8sD_iAek"
   },
   "source": [
    "Similar to Recitation 2, we first sample some polar co-ordinates that are randomly distributed within a circle of radius 2 and centered at origin, ie. $(0,0)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GIvpTW7giAel"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def sample_points(n):\n",
    "    \"\"\"\n",
    "    :param n: Total number of data-points\n",
    "    :return: A tuple (X,y) where X is a float tensor with shape (n,2)\n",
    "               and y is an interger tensor with shape(n,)\n",
    "    \"\"\"    \n",
    "    radius = torch.rand(n) * 2\n",
    "    angle = torch.rand(n) * 2 * math.pi\n",
    "    x1 = radius * angle.cos()\n",
    "    x2 = radius * angle.sin()\n",
    "    y = radius < 1\n",
    "    x = torch.stack([x1, x2], dim=1)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3229,
     "status": "ok",
     "timestamp": 1568841355900,
     "user": {
      "displayName": "Liwei Cai",
      "photoUrl": "",
      "userId": "16466533746106471957"
     },
     "user_tz": 240
    },
    "id": "1JXyeDBkiAeq",
    "outputId": "5cac8bca-59fa-4287-c7fd-4e9f4c5266b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 2]) torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "# Generating the data\n",
    "\n",
    "X_train, y_train = sample_points(1000)\n",
    "X_val,y_val = sample_points(500)\n",
    "\n",
    "print(X_train.size(), y_train.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3227,
     "status": "ok",
     "timestamp": 1568841355900,
     "user": {
      "displayName": "Liwei Cai",
      "photoUrl": "",
      "userId": "16466533746106471957"
     },
     "user_tz": 240
    },
    "id": "IxjmcoMDrojK",
    "outputId": "59a6457e-d704-4dd1-dd2e-2dcc249479dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=2, out_features=12, bias=True)\n",
      "  (1): Sigmoid()\n",
      "  (2): Linear(in_features=12, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Build a simple MLP\n",
    "def build_model(dims, activation):\n",
    "    layers = []\n",
    "    for i in range(len(dims) - 1):\n",
    "        layers.append(nn.Linear(dims[i], dims[i + 1]))\n",
    "        if i < len(dims) - 2:\n",
    "            layers.append(activation())\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "# Test the function\n",
    "print(build_model([2, 12, 1], nn.Sigmoid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "moSbTVIziAeb"
   },
   "source": [
    "A SummaryWriter writes all values we want to visualize to a given directory. This line creates a SummaryWriter that creates write event files and saves in the `./runs/example` directory.\n",
    "```python\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(\"./runs/example\")\n",
    "```\n",
    "You should use different run directories in a common root directory for different runs of your model. TensorBoard looks for runs in the root directory. So for this example, we start the TensorBoard with:\n",
    "\n",
    "```sh\n",
    "tensorboard --logdir=./runs\n",
    "```\n",
    "Then, visit `localhost:6006` with your browser to see the TensorBoard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q7l7fn7viAe0"
   },
   "source": [
    "Each time we add a value, we specify a **tag** and a **step**. Each tag is a string and corresponds to a plot on TensorBoard. The step is an integer (`epoch` in this example) that serves as the X axis on the plot.\n",
    "\n",
    "To plot a single scalar, use [*SummaryWriter.add_scalar()*](https://pytorch.org/docs/stable/tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_scalar). To plot multiple scalars on a plot, use [*SummaryWriter.add_scalars()*](https://pytorch.org/docs/stable/tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_scalars) and pass in a dict of scalars.\n",
    "\n",
    "Using [*SummaryWriter.add_histogram()*](https://pytorch.org/docs/stable/tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_histogram) to plot a histogram of values in a tensor is also useful for understanding the dynamics of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6cat4BvXxn3Z"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train(model, writer, epochs=1000):\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        model.zero_grad()\n",
    "        out = model(X_train).flatten()\n",
    "        loss = criterion(out, y_train.float())\n",
    "        train_loss = loss.item()\n",
    "        train_acc = ((out > 0) == y_train).float().mean().item()\n",
    "\n",
    "        loss.backward()\n",
    "        # Plot histogram of gradient of all parameters\n",
    "        for name, param in model.named_parameters():\n",
    "            writer.add_histogram('grad_' + name, param.grad.data, epoch)\n",
    "        optimizer.step()\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            out = model(X_val).flatten()\n",
    "            val_loss = criterion(out, y_val.float()).item()\n",
    "            val_acc = ((out > 0) == y_val).float().mean().item()\n",
    "        # Plot loss and accuracy on train and val\n",
    "        writer.add_scalars('loss', {'train': train_loss, 'val': val_loss}, epoch)\n",
    "        writer.add_scalars('acc', {'train': train_acc, 'val': val_acc}, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HWJ8UNjFiAfA"
   },
   "source": [
    "## Using Different Activation functions\n",
    "\n",
    "Let's see and understand how each of these activation functions perform.\n",
    "\n",
    "- Sigmoid\n",
    "    * Get values between 0 and 1.\n",
    "    * A Sigmoid layer easily dies or saturates. A value too small kills the gradient flow whereas a value too big saturates the neurons, effectively passing no information through it.\n",
    "    \n",
    "- Tanh\n",
    "    * Outputs values between -1 and 1. Also zero centered and so does not have the problem of all positive/negative gradients.\n",
    "    * Better than Sigmoid but problem of saturation persists.\n",
    "\n",
    "- ReLU\n",
    "    * Converges quickly as is a threshold based activation and does not saturate.\n",
    "    * Neurons die off. Large weight update could set the weights in such a way (they become negative) during backpropagation that they never fire for any data point. Important to set lower learning rates for ReLU.\n",
    "    \n",
    "    \n",
    "**TRY IT OUT**\n",
    "\n",
    "Use all the 3 activation functions. See which performs better and try to find out why. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 45823,
     "status": "ok",
     "timestamp": 1568841398500,
     "user": {
      "displayName": "Liwei Cai",
      "photoUrl": "",
      "userId": "16466533746106471957"
     },
     "user_tz": 240
    },
    "id": "YXJykUfUiAfU",
    "outputId": "92382484-1f24-4ab2-9dbb-55aab719eba2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:09<00:00, 107.35it/s]\n",
      "100%|██████████| 1000/1000 [00:11<00:00, 85.39it/s]\n",
      "100%|██████████| 1000/1000 [00:11<00:00, 86.21it/s]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(\"./runs/sigmoid\")\n",
    "model = build_model([2, 12, 1], nn.Sigmoid)\n",
    "train(model, writer)\n",
    "\n",
    "writer = SummaryWriter(\"./runs/tanh\")\n",
    "model = build_model([2, 12, 1], nn.Tanh)\n",
    "train(model, writer)\n",
    "\n",
    "writer = SummaryWriter(\"./runs/relu\")\n",
    "model = build_model([2, 12, 1], nn.ReLU)\n",
    "train(model, writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TZqK0YxbNoZm"
   },
   "source": [
    "Open TensorBoard and see the result!\n",
    "\n",
    "![TensorBoard: accuracy](tensorboard_acc.png)\n",
    "\n",
    "![TensorBoard: gradient distribution](tensorboard_grad.png)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DataVisualization.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
