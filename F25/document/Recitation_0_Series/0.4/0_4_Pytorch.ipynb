{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](\n",
        "https://colab.research.google.com/github/CMU-IDeeL/CMU-IDeeL.github.io/blob/master/F25/document/Recitation_0_Series/0.4/0_4_Pytorch.ipynb)"
      ],
      "metadata": {
        "id": "kzL-P_qnq9BZ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nMtWnwwm-gF"
      },
      "source": [
        "# **Exercise for Introduction to PyTorch Fundamentals**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LT1YCYN4m-gI"
      },
      "source": [
        "### IMPORTANT NOTE: To avoid version mismatch errors with Autolab, please ensure you are using commands that are from the following versions of [*NumPy*](https://numpy.org/) and [*Torch*](https://pytorch.org/) :    \n",
        "`numpy==1.16.4`  \n",
        "`torch==1.2.0`  \n",
        "if your installation fails, make sure you are using a virtual environment with `python v3.7.13` installed\n",
        "  \n",
        "For example,\n",
        "Consider using `torch.mul(x, y)` instead of `torch.multiply(x, y)`.\n",
        "\n",
        "Why? `torch.mul(x, y)` is available in version `torch==1.2.0`, whereas `torch.multiply(x, y)` is not. Using `torch==1.2.0` will help us avoid unpleasant issues with AutoLab's default versioning.\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llpFMKCwm-gI"
      },
      "source": [
        "> PyTorch is an open source deep learning platform that provides a seamless path from research prototyping to production deployment.\n",
        "> - *Hybrid Front-End:* A new hybrid front-end seamlessly transitions between eager mode and graph mode to provide both flexibility and speed.\n",
        "> - *Distributed Training:* Scalable distributed training and performance optimization in research and production is enabled by the torch.distributed backend.\n",
        "> - *Python-First:* Deep integration into Python allows popular libraries and packages to be used for easily writing neural network layers in Python.\n",
        "> - *Tools & Libraries:* A rich ecosystem of tools and libraries extends PyTorch and supports development in computer vision, NLP and more.\n",
        ">\n",
        "> â€”*[About PyTorch](https://pytorch.org/)*\n",
        "\n",
        "One consideration as to why we are using PyTorch is most succinctly summerized by Andrej Karpathy, Former Director of Artificial Intelligence and Autopilot Vision at Tesla. The technical summary can be found [here](https://twitter.com/karpathy/status/868178954032513024?lang=en).\n",
        "\n",
        "You also refer a brief summary on PyTorch by Nvidia [here](https://www.nvidia.com/en-us/glossary/data-science/pytorch/).\n",
        "\n",
        "For this notebook you can refer to the documentation provided by PyTorch [here](https://pytorch.org/docs/stable/nn.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FmSsfMaAm-gJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d1669ee-3d68-47f0-e0bb-bdf0eb13becb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.2\n",
            "2.6.0+cu124\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "print(np.__version__)\n",
        "import os\n",
        "import time\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "\n",
        "# Expected outputs for local (used for HW part1s):\n",
        "# 1.16.4\n",
        "# 1.2.0\n",
        "\n",
        "# Expected outputs for colab (used for HW part2s):\n",
        "# 1.23.5\n",
        "# 2.1.0+cu121"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qdEM_GTm-gK"
      },
      "source": [
        "### **1. Interconversion**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtd1mrZom-gL"
      },
      "source": [
        "#### 1.1 Converting from NumPy to PyTorch Tensor\n",
        "\n",
        "*   List item\n",
        "*   List item\n",
        "\n",
        "\n",
        "In this task, you will implement a conversion function from arrays to tensors.\n",
        "\n",
        "The function should take a numpy ndarray and convert it to a PyTorch tensor.\n",
        "\n",
        "*Function torch.tensor is one of the simple ways to implement it but please do not use it this time. The PyTorch environment installed on Autolab is not an up-to-date version and does not support this function.*\n",
        "\n",
        "**Your Task**: Implement the function `numpy2tensor`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AOztJhtsm-gL"
      },
      "outputs": [],
      "source": [
        "def numpy2tensor(x):\n",
        "    \"\"\"\n",
        "    Creates a torch.Tensor from a numpy.ndarray.\n",
        "\n",
        "    Parameters:\n",
        "    x (numpy.ndarray): 1-dimensional numpy array.\n",
        "\n",
        "    Returns:\n",
        "    torch.Tensor: 1-dimensional torch tensor.\n",
        "    \"\"\"\n",
        "\n",
        "    return  torch.tensor(x) #NotImplemented   # TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-CCu4Ibm-gL"
      },
      "source": [
        "##### Test Example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EySRUXjCm-gL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78d40d10-cc28-4456-cf9c-820e5c68c9b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n"
          ]
        }
      ],
      "source": [
        "X = np.random.randint(-1000, 1000, size=3000)\n",
        "\n",
        "print(type(numpy2tensor(X)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7rVaFHim-gM"
      },
      "source": [
        "**Expected Output**:\n",
        "<table style = \"align:40%\">\n",
        "    <tr>\n",
        "        <td style=\"text-align:left;\"><tt> &lt;class &#39;torch.Tensor&#39;&gt; </tt></td>\n",
        "    </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yy63znfRm-gM"
      },
      "source": [
        "#### 1.2 Converting from PyTorch Tensor to NumPy\n",
        "\n",
        "In this task, you will implement a conversion function from tensors to arrays.\n",
        "\n",
        "The function should take a PyTorch tensor and convert it to a numpy ndarray.\n",
        "\n",
        "**Your Task**: Implement the function `tensor2numpy`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVy1x9pem-gM"
      },
      "outputs": [],
      "source": [
        "def tensor2numpy(x):\n",
        "    \"\"\"\n",
        "    Creates a numpy.ndarray from a torch.Tensor.\n",
        "\n",
        "    Parameters:\n",
        "    x (torch.Tensor): 1-dimensional torch tensor.\n",
        "\n",
        "    Returns:\n",
        "    numpy.ndarray: 1-dimensional numpy array.\n",
        "    \"\"\"\n",
        "\n",
        "    return NotImplemented  # TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekVnQTUHm-gM"
      },
      "source": [
        "##### Test Example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QFNQcTS8m-gN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "711d4fce-d7e1-45e8-86bf-1a5142129ee0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'NotImplementedType'>\n"
          ]
        }
      ],
      "source": [
        "X = np.random.randint(-1000, 1000, size=3000)\n",
        "X = torch.from_numpy(X)\n",
        "\n",
        "print(type(tensor2numpy(X)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJ-AbDmvm-gN"
      },
      "source": [
        "**Expected Output**:\n",
        "<table style = \"align:40%\">\n",
        "    <tr>\n",
        "        <td style=\"text-align:left;\"><tt> &lt;class &#39;numpy.ndarray&#39;&gt; </tt></td>\n",
        "    </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulMyp9z6m-gN"
      },
      "source": [
        "### **2. Vectorization**\n",
        "\n",
        "Lists are a foundational data structure in Python, allowing us to create simple and complex algorithms to solve problems. However, in mathematics and particularly in linear algebra, we work with vectors and matrices to model problems and create statistical solutions. Through these exercises, we will begin introducing you to how to think more mathematically through the use of PyTorch by starting with a process known as vectorization.\n",
        "\n",
        "Index chasing is a very valuable skill, and certainly one you will need in this course, but mathematical problems often have simpler and more efficient representations that use vectors. The process of converting from an implimentation that uses indicies to one that uses vectors is known as vectorization. Once vectorized, the resulting implementation often yields to the user faster and more readable code than before.\n",
        "\n",
        "In the following problems, we will ask you to practice reading mathematical expressions and deduce their vectorized equivalent along with their implementation in Python. You will use the PyTorch array object as the Python equivalent to a vector, and in later sections you will work with sets of vectors known as matrices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pwJu6cNAm-gO"
      },
      "outputs": [],
      "source": [
        "def PYTORCH_dot(x, y):\n",
        "    \"\"\"\n",
        "    Dot product of two tensors.\n",
        "\n",
        "    Parameters:\n",
        "    x (torch.Tensor): 1-dimensional torch tensor.\n",
        "    y (torch.Tensor): 1-dimensional torch tensor.\n",
        "\n",
        "    Returns:\n",
        "    torch.int64: scalar quantity.\n",
        "    \"\"\"\n",
        "\n",
        "    return NotImplemented   # TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGgHsqmDm-gO"
      },
      "source": [
        "##### Test Example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JqUL7tQCm-gO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a76d75db-68ef-49ec-9166-3bef61bc07db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NotImplemented\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(0)\n",
        "X = np.random.randint(-1000, 1000, size=3000)\n",
        "Y = np.random.randint(-1000, 1000, size=3000)\n",
        "\n",
        "\n",
        "X = numpy2tensor(X)\n",
        "Y = numpy2tensor(Y)\n",
        "\n",
        "print(PYTORCH_dot(X,Y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p17MVBlPm-gO"
      },
      "source": [
        "**Expected Output**:\n",
        "<table style = \"align:40%\">\n",
        "    <tr>\n",
        "        <td style=\"text-align:left;\"><tt><b> PYTORCH_dot(X,Y) </b></tt></td>\n",
        "        <td style=\"text-align:left;\"><tt> 7082791 </tt></td>\n",
        "    </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OehfROg0m-gO"
      },
      "source": [
        "#### 2.2 Outer Product\n",
        "\n",
        "In this task, you will implement the outer product function for torch tensors.\n",
        "\n",
        "The outer product (also known as the tensor product) of vectors x and y is defined as\n",
        "\n",
        "$$\n",
        "x \\otimes y =\n",
        "\\begin{bmatrix}\n",
        "x_1 y_1 & x_1 y_2 & â€¦ & x_1 y_n\\\\\n",
        "x_2 y_1 & x_2 y_2 & â€¦ & x_2 y_n\\\\\n",
        "â‹® & â‹® & â‹± & â‹® \\\\\n",
        "x_m y_1 & x_m y_2 & â€¦ & x_m y_n\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "**Your Task**: Implement the function `PYTORCH_outer`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lz7bIeLgm-gP"
      },
      "outputs": [],
      "source": [
        "def PYTORCH_outer(x, y):\n",
        "    \"\"\"\n",
        "    Compute the outer product of two vectors.\n",
        "\n",
        "    Parameters:\n",
        "    x (torch.Tensor): 1-dimensional torch tensor.\n",
        "    y (torch.Tensor): 1-dimensional torch tensor.\n",
        "\n",
        "    Returns:\n",
        "    torch.Tensor: 2-dimensional torch tensor.\n",
        "    \"\"\"\n",
        "\n",
        "    return NotImplemented   # TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMNJF977m-gP"
      },
      "source": [
        "##### Test Example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hR7BfA3im-gP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51b55257-74e0-4e6a-bed0-79b6bfb5e640"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NotImplemented\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(0)\n",
        "X = np.random.randint(-1000, 1000, size=3000)\n",
        "Y = np.random.randint(-1000, 1000, size=3000)\n",
        "\n",
        "\n",
        "X = numpy2tensor(X)\n",
        "Y = numpy2tensor(Y)\n",
        "\n",
        "print(PYTORCH_outer(X,Y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nio3SbQim-gP"
      },
      "source": [
        "**Expected Output**:\n",
        "<table style = \"align:40%\">\n",
        "    <tr>\n",
        "        </tt></td>\n",
        "        <td style=\"text-align:left;\"><tt><b> PYTORCH_outer(X,Y) </b></tt></td>\n",
        "        <td style=\"text-align:left;\"><tt>\n",
        "            [[&nbsp;&nbsp;59092&nbsp;-144096&nbsp;&nbsp;136512&nbsp;...&nbsp;&nbsp;-53088&nbsp;&nbsp;-86268&nbsp;&nbsp;&nbsp;53404] <br>\n",
        "            &nbsp;[&nbsp;&nbsp;82467&nbsp;-201096&nbsp;&nbsp;190512&nbsp;...&nbsp;&nbsp;-74088&nbsp;-120393&nbsp;&nbsp;&nbsp;74529] <br>\n",
        "            &nbsp;[-122111&nbsp;&nbsp;297768&nbsp;-282096&nbsp;...&nbsp;&nbsp;109704&nbsp;&nbsp;178269&nbsp;-110357] <br>\n",
        "            &nbsp;... <br>\n",
        "            &nbsp;[-144551&nbsp;&nbsp;352488&nbsp;-333936&nbsp;...&nbsp;&nbsp;129864&nbsp;&nbsp;211029&nbsp;-130637] <br>\n",
        "            &nbsp;[-179707&nbsp;&nbsp;438216&nbsp;-415152&nbsp;...&nbsp;&nbsp;161448&nbsp;&nbsp;262353&nbsp;-162409] <br>\n",
        "            &nbsp;[&nbsp;&nbsp;88825&nbsp;-216600&nbsp;&nbsp;205200&nbsp;...&nbsp;&nbsp;-79800&nbsp;-129675&nbsp;&nbsp;&nbsp;80275]] <br>\n",
        "        </tt></td>\n",
        "    </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GoF1xUtem-gP"
      },
      "source": [
        "#### 2.3 Hadamard Product\n",
        "\n",
        "In this task, you will implement the Hadamard product function, `multiply`, for torch tensors.\n",
        "\n",
        "The Hadamard product (also known as the Schur product or entrywise product) of vectors x and y is defined as\n",
        "\n",
        "$$\n",
        "x \\circ y =\n",
        "\\begin{bmatrix}\n",
        "x_{1} y_{1} & x_{2} y_{2} & â€¦ & x_{n} y_{n}\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "**Your Task**: Implement the function `PYTORCH_multiply`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_qwqp2ym-gP"
      },
      "outputs": [],
      "source": [
        "def PYTORCH_multiply(x, y):\n",
        "    \"\"\"\n",
        "    Multiply arguments element-wise.\n",
        "\n",
        "    Parameters:\n",
        "    x (torch.Tensor): 1-dimensional torch tensor.\n",
        "    y (torch.Tensor): 1-dimensional torch tensor.\n",
        "\n",
        "    Returns:\n",
        "    torch.Tensor: 1-dimensional torch tensor.\n",
        "    \"\"\"\n",
        "\n",
        "    return NotImplemented   # TODO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BqU2UtZAm-gQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04e323b1-ec2a-485b-df03-001795598ab0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NotImplemented\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(0)\n",
        "X = np.random.randint(-1000, 1000, size=3000)\n",
        "Y = np.random.randint(-1000, 1000, size=3000)\n",
        "\n",
        "\n",
        "X = numpy2tensor(X)\n",
        "Y = numpy2tensor(Y)\n",
        "\n",
        "print(PYTORCH_multiply(X,Y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jLobTUMm-gQ"
      },
      "source": [
        "**Expected Output**:\n",
        "<table style = \"align:40%\">\n",
        "    <tr>\n",
        "        <td style=\"text-align:left;\"><tt><b> PYTORCH_multiply(X,Y) </b></tt></td>\n",
        "        <td style=\"text-align:left;\"><tt>\n",
        "            [&nbsp;&nbsp;59092&nbsp;-201096&nbsp;-282096&nbsp;...&nbsp;&nbsp;129864&nbsp;&nbsp;262353&nbsp;&nbsp;&nbsp;80275]\n",
        "        </tt></td>\n",
        "    </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y281rHuem-gQ"
      },
      "source": [
        "#### 2.4 Sum-Product\n",
        "In this task, you will implement the sum-product function for torch tensors.\n",
        "\n",
        "The sum-product of vectors x and y, each with n real component, is defined as\n",
        "\n",
        "$$\n",
        "f(x, y) =\n",
        "{\n",
        "\\begin{bmatrix}\n",
        "1\\\\\n",
        "1\\\\\n",
        "â‹®\\\\\n",
        "1\n",
        "\\end{bmatrix}^{\\;T}\n",
        "%\n",
        "\\begin{bmatrix}\n",
        "x_1 y_1 & x_1 y_2 & â€¦ & x_1 y_n\\\\\n",
        "x_2 y_1 & x_2 y_2 & â€¦ & x_2 y_n\\\\\n",
        "â‹® & â‹® & â‹± & â‹® \\\\\n",
        "x_m y_1 & x_m y_2 & â€¦ & x_m y_n\n",
        "\\end{bmatrix}\n",
        "%\n",
        "\\begin{bmatrix}\n",
        "1\\\\\n",
        "1\\\\\n",
        "â‹®\\\\\n",
        "1\n",
        "\\end{bmatrix}\n",
        "} =\n",
        "\\displaystyle\\sum_{i=1}^{n} \\displaystyle\\sum_{j=1}^{n} x_i \\cdot y_j\n",
        "$$\n",
        "\n",
        "**Your Task**: Implement the function `PYTORCH_sumproduct`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4zyqcVJPm-gQ"
      },
      "outputs": [],
      "source": [
        "def PYTORCH_sumproduct(x, y):\n",
        "    \"\"\"\n",
        "    Sum over all the dimensions of the outer product of two vectors.\n",
        "\n",
        "    Parameters:\n",
        "    x (torch.Tensor): 1-dimensional torch tensor.\n",
        "    y (torch.Tensor): 1-dimensional torch tensor.\n",
        "\n",
        "    Returns:\n",
        "    torch.int64: scalar quantity.\n",
        "    \"\"\"\n",
        "\n",
        "    return  NotImplemented   # TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ixn7jT8Xm-gQ"
      },
      "source": [
        "##### Test Example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uk_y45xYm-gR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f9a5407-8db5-4935-e2aa-73adcac17689"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NotImplemented\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(0)\n",
        "X = np.random.randint(-1000, 1000, size=3000)\n",
        "Y = np.random.randint(-1000, 1000, size=3000)\n",
        "\n",
        "X = numpy2tensor(X)\n",
        "Y = numpy2tensor(Y)\n",
        "\n",
        "print(PYTORCH_sumproduct(X,Y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXl3lBNEm-gR"
      },
      "source": [
        "**Expected Output**:\n",
        "<table style = \"align:40%\">\n",
        "    <tr>\n",
        "        <td style=\"text-align:left;\"><tt><b> TORCH_sumproduct(X,Y) </b></tt></td>\n",
        "        <td style=\"text-align:left;\"><tt> 265421520 </tt></td>\n",
        "    </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rljBFhfIm-gS"
      },
      "source": [
        "#### 2.5 ReLU\n",
        "\n",
        "In this task, you will implement the ReLU activation function torch tensors.\n",
        "\n",
        "The ReLU activation (also known as the rectifier or rectified linear unit) matrix Z resulting from applying the ReLU function to matrix X is defined such that for $X,Z \\in M_{m \\times n} (\\mathbb{R})$,\n",
        "\n",
        "\n",
        "**Your Task:** Implement the function `PYTORCH_ReLU`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nfaJ0bjNm-gS"
      },
      "outputs": [],
      "source": [
        "def PYTORCH_ReLU(x):\n",
        "    \"\"\"\n",
        "    Applies the rectified linear unit function element-wise.\n",
        "\n",
        "    Parameters:\n",
        "    x (torch.Tensor): 2-dimensional torch tensor.\n",
        "\n",
        "    Returns:\n",
        "    torch.Tensor: 2-dimensional torch tensor.\n",
        "    \"\"\"\n",
        "\n",
        "    return NotImplemented   # TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGr4rDIum-gS"
      },
      "source": [
        "##### Test Example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JIrL1jfum-gT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4aaccf4f-b107-4c4b-cc27-6c1e3ee458df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NotImplemented\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(0)\n",
        "X = np.random.randint(-1000, 1000, size=(3000,3000))\n",
        "\n",
        "\n",
        "X = numpy2tensor(X)\n",
        "\n",
        "print(PYTORCH_ReLU(X))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qs1Imk9Mm-gT"
      },
      "source": [
        "**Expected Output**:\n",
        "<table style = \"align:40%\">\n",
        "    <tr>\n",
        "        </tt></td>\n",
        "        <td style=\"text-align:left;\"><tt><b> PYTORCH_ReLU(X) </b></tt></td>\n",
        "        <td style=\"text-align:left;\"><tt>\n",
        "            [[&nbsp;&nbsp;0&nbsp;&nbsp;&nbsp;0&nbsp;653&nbsp;...&nbsp;773&nbsp;961&nbsp;&nbsp;&nbsp;0] <br>\n",
        "&nbsp;[&nbsp;&nbsp;0&nbsp;456&nbsp;&nbsp;&nbsp;0&nbsp;...&nbsp;168&nbsp;273&nbsp;&nbsp;&nbsp;0] <br>\n",
        "&nbsp;[936&nbsp;475&nbsp;&nbsp;&nbsp;0&nbsp;...&nbsp;408&nbsp;&nbsp;&nbsp;0&nbsp;&nbsp;&nbsp;0] <br>\n",
        "&nbsp;... <br>\n",
        "&nbsp;[&nbsp;&nbsp;0&nbsp;396&nbsp;457&nbsp;...&nbsp;646&nbsp;&nbsp;&nbsp;0&nbsp;&nbsp;&nbsp;0] <br>\n",
        "&nbsp;[645&nbsp;943&nbsp;&nbsp;&nbsp;0&nbsp;...&nbsp;863&nbsp;&nbsp;&nbsp;0&nbsp;790] <br>\n",
        "&nbsp;[641&nbsp;&nbsp;&nbsp;0&nbsp;379&nbsp;...&nbsp;347&nbsp;&nbsp;&nbsp;0&nbsp;&nbsp;&nbsp;0]]\n",
        "        </tt></td>\n",
        "    </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFlfBxn9m-gT"
      },
      "source": [
        "#### 2.6 Prime ReLU (derivative of ReLU)\n",
        "\n",
        "In this task, you will implement the derivative of the ReLU activation function for torch tensors.\n",
        "\n",
        "The derivative of the ReLU activation matrix Z resulting from applying the derivative of the ReLU function to matrix X is defined such that for $X,Z \\in M_{m \\times n} (\\mathbb{R})$,\n",
        "\n",
        "\n",
        "\n",
        "**Your Task:** Implement the function `PYTORCH_PrimeReLU`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ar0b8Cmom-gU"
      },
      "outputs": [],
      "source": [
        "def PYTORCH_PrimeReLU(x):\n",
        "    \"\"\"\n",
        "    Applies the derivative of the rectified linear unit function\n",
        "    element-wise.\n",
        "\n",
        "    Parameters:\n",
        "    x (numpy.ndarray): 2-dimensional torch tensor.\n",
        "\n",
        "    Returns:\n",
        "    numpy.ndarray: 2-dimensional torch tensor.\n",
        "    \"\"\"\n",
        "    # TODO\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4-Tsua7m-gU"
      },
      "source": [
        "##### Test Example:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E6FtWmGJm-gU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6740f25b-12cd-4459-ffe2-63dde60c202d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-316, -441,  653,  ...,  773,  961, -475],\n",
            "        [-187,  456, -432,  ...,  168,  273, -169],\n",
            "        [ 936,  475, -128,  ...,  408, -892, -310],\n",
            "        ...,\n",
            "        [-921,  396,  457,  ...,  646, -450, -387],\n",
            "        [ 645,  943, -435,  ...,  863, -920,  790],\n",
            "        [ 641, -548,  379,  ...,  347,  -67, -352]])\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(0)\n",
        "X = np.random.randint(-1000, 1000, size=(3000,3000))\n",
        "\n",
        "X = numpy2tensor(X)\n",
        "\n",
        "print(PYTORCH_PrimeReLU(X))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65FcTZOFm-gV"
      },
      "source": [
        "**Expected Output**:\n",
        "<table style = \"align:40%\">\n",
        "    <tr>\n",
        "        <td style=\"text-align:left;\"><tt><b> PYTORCH_PrimeReLU(X) </b></tt></td>\n",
        "        <td style=\"text-align:left;\"><tt>\n",
        "            [[0&nbsp;0&nbsp;1&nbsp;...&nbsp;1&nbsp;1&nbsp;0] <br>\n",
        "&nbsp;[0&nbsp;1&nbsp;0&nbsp;...&nbsp;1&nbsp;1&nbsp;0] <br>\n",
        "&nbsp;[1&nbsp;1&nbsp;0&nbsp;...&nbsp;1&nbsp;0&nbsp;0] <br>\n",
        "&nbsp;... <br>\n",
        "&nbsp;[0&nbsp;1&nbsp;1&nbsp;...&nbsp;1&nbsp;0&nbsp;0] <br>\n",
        "&nbsp;[1&nbsp;1&nbsp;0&nbsp;...&nbsp;1&nbsp;0&nbsp;1] <br>\n",
        "&nbsp;[1&nbsp;0&nbsp;1&nbsp;...&nbsp;1&nbsp;0&nbsp;0]]\n",
        "        </tt></td>\n",
        "    </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3EBsZsim-gV"
      },
      "source": [
        "### **3. Tensor Manipulation**\n",
        "\n",
        "PyTorch offers a wide range of tensor manipulation tasks that empower users to efficiently process and transform data within neural network workflows.\n",
        "These tasks include :\n",
        "1.  Flatten\n",
        "2.  Unsqueeze\n",
        "3.  Squeeze\n",
        "4.  Reshape\n",
        "5.  Transpose\n",
        "6.  Permute\n",
        "7.  Concatenation\n",
        "8.  Stack\n",
        "9.  Padding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIzGVjK0m-gW"
      },
      "source": [
        "#### 3.1 Flatten\n",
        "\n",
        "In this task, you will implement the flatten function for torch tensors.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Your Task:** Implement the function `PYTORCH_flatten`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bG7H_5ahm-gW"
      },
      "outputs": [],
      "source": [
        "def PYTORCH_flatten(input_tensor):\n",
        "    \"\"\"\n",
        "    Reshapes a tensor into a 1-dimensional array while maintaining the order of elements.\n",
        "\n",
        "    Parameters:\n",
        "    x (torch.Tensor): 3-dimensional torch tensor.\n",
        "\n",
        "    Returns:\n",
        "    torch.Tensor: 1-dimensional torch tensor.\n",
        "    \"\"\"\n",
        "    m = torch.nn.Flatten()\n",
        "    return m(input_tensor)\n",
        "    # return NotImplemented #TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckVHYbr-m-gW"
      },
      "source": [
        "##### Test Example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6AxIPmtdm-gW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "892ccdcf-beda-4241-cbd3-350636a237ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  2,   5, -10,  ...,  -2,   4,   2],\n",
            "        [  3,  -9,   3,  ...,   4,   3,   6],\n",
            "        [  4,   9,   9,  ...,   7,  -4,   9],\n",
            "        ...,\n",
            "        [ -7,   1,   2,  ...,   3,  -2,   4],\n",
            "        [  1,  -8,  -2,  ...,  -5,  -6,   7],\n",
            "        [ -4,  -6,  -3,  ...,   1,   3,  -3]])\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(0)\n",
        "X = np.random.randint(-10, 10, size=(100,100,100))\n",
        "\n",
        "X = numpy2tensor(X)\n",
        "\n",
        "print(PYTORCH_flatten(X))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNsni2Bhm-gW"
      },
      "source": [
        "**Expected Output**:\n",
        "<table style = \"align:40%\">\n",
        "    <tr>\n",
        "        <td style=\"text-align:left;\"><tt><b> PYTORCH_flatten(X) </b></tt></td>\n",
        "        <td style=\"text-align:left;\"><tt>\n",
        "            [  2,   5, -10,  ...,   1,   3,  -3]\n",
        "        </tt></td>\n",
        "    </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xEP2bXom-gW"
      },
      "source": [
        "#### 3.2 Unsqueeze\n",
        "\n",
        "In this task, you will implement the unsqueeze function for torch tensors along given dimension.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Your Task:** Implement the function `PYTORCH_unsqueeze`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JWiQtP-Tm-gW"
      },
      "outputs": [],
      "source": [
        "def PYTORCH_unsqueeze(X,dim):\n",
        "    \"\"\"\n",
        "    Adds a new dimension to a tensor at the specified position 'dim'.\n",
        "\n",
        "    Parameters:\n",
        "    x (torch.Tensor): 2-dimensional torch tensor.\n",
        "\n",
        "    dim (int): scalar.\n",
        "\n",
        "    Returns:\n",
        "    torch.Tensor: 3-dimensional torch tensor.\n",
        "    \"\"\"\n",
        "\n",
        "    return NotImplemented #TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hu-n1qoom-gW"
      },
      "source": [
        "##### Test Example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ERwRMBmim-gW",
        "outputId": "c57a5078-3a17-4838-b29e-992f1a22e426",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NotImplemented\n",
            "\n",
            "\n",
            "Shape before unsqueeze:  torch.Size([100, 100])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'NotImplementedType' object has no attribute 'shape'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-21-3430553286.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Shape before unsqueeze: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Shape after unsqueeze: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mPYTORCH_unsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'NotImplementedType' object has no attribute 'shape'"
          ]
        }
      ],
      "source": [
        "np.random.seed(0)\n",
        "X = np.random.randint(0, 5, size=(100,100))\n",
        "\n",
        "X = numpy2tensor(X)\n",
        "\n",
        "print(PYTORCH_unsqueeze(X,0))\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Shape before unsqueeze: \",X.shape)\n",
        "print(\"Shape after unsqueeze: \",PYTORCH_unsqueeze(X,0).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-bSSKHwm-gX"
      },
      "source": [
        "**Expected Output**:\n",
        "<table style = \"align:40%\">\n",
        "    <tr>\n",
        "        <td style=\"text-align:left;\"><tt><b> PYTORCH_unsqueeze(X) </b></tt></td>\n",
        "        <td style=\"text-align:left;\"><tt>\n",
        "        [[[4&nbsp;0&nbsp;3&nbsp;...&nbsp;2&nbsp;2&nbsp;3] <br>\n",
        "&nbsp; [2&nbsp;3&nbsp;2&nbsp;...&nbsp;2&nbsp;3&nbsp;3] <br>\n",
        "&nbsp; [1&nbsp;3&nbsp;4&nbsp;...&nbsp;0&nbsp;2&nbsp;4] <br>\n",
        "&nbsp; ..., <br>\n",
        "&nbsp; [2&nbsp;0&nbsp;1&nbsp;...&nbsp;4&nbsp;4&nbsp;3] <br>\n",
        "&nbsp; [2&nbsp;4&nbsp;3&nbsp;...&nbsp;3&nbsp;0&nbsp;0] <br>\n",
        "&nbsp; [2&nbsp;3&nbsp;4&nbsp;...&nbsp;4&nbsp;3&nbsp;1]]]<br>\n",
        "<br>\n",
        "Shape before unsqueeze:  torch.Size([100, 100]) <br>\n",
        "Shape after unsqueeze:  torch.Size([1, 100, 100])\n",
        "        </tt></td>\n",
        "    </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvx93Rb7m-gX"
      },
      "source": [
        "#### 3.3 Squeeze\n",
        "\n",
        "In this task, you will implement the squeeze function for torch tensors along axis with dimension 1 (axis = 0).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Your Task:** Implement the function `PYTORCH_squeeze`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EK92xdp9m-gX"
      },
      "outputs": [],
      "source": [
        "def PYTORCH_squeeze(X,dim):\n",
        "    \"\"\"\n",
        "    Removes dimension to a tensor at the specified position 'dim'.\n",
        "\n",
        "    Parameters:\n",
        "    x (torch.Tensor): 2-dimensional torch tensor.\n",
        "\n",
        "    dim (integer): scalar.\n",
        "\n",
        "    Returns:\n",
        "    torch.Tensor: 1-dimensional torch tensor.\n",
        "    \"\"\"\n",
        "\n",
        "    return NotImplemented #TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsaF2J-7m-gX"
      },
      "source": [
        "#### Test Example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMD-i948m-gX"
      },
      "outputs": [],
      "source": [
        "np.random.seed(0)\n",
        "X = np.random.randint(0, 10, size=(1,5))\n",
        "\n",
        "X = numpy2tensor(X)\n",
        "\n",
        "\n",
        "\n",
        "print(PYTORCH_squeeze(X,0))\n",
        "\n",
        "print(\"Shape of tensor before squeeze: \",X.shape)\n",
        "print(\"Shape of tensor after squeeze: \",PYTORCH_squeeze(X,0).shape )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32q8s3Aym-gY"
      },
      "source": [
        "**Expected Output**:\n",
        "<table style = \"align:40%\">\n",
        "    <tr>\n",
        "        <td style=\"text-align:left;\"><tt><b> PYTORCH_squeeze(X) </b></tt></td>\n",
        "        <td style=\"text-align:left;\"><tt>\n",
        "        [5&nbsp;0&nbsp;3&nbsp;3&nbsp;7&nbsp;] <br>\n",
        "Shape of tensor before squeeze:  torch.Size([1, 5]) <br>\n",
        "Shape of tensor after squeeze:  torch.Size([5])\n",
        "        </tt></td>\n",
        "    </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzHpPfoWm-gY"
      },
      "source": [
        "#### 3.4 Reshape\n",
        "\n",
        "In this task, you will implement the reshape function for torch tensors.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Your Task:** Implement the function `PYTORCH_reshape`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jij9cDVIm-gY"
      },
      "outputs": [],
      "source": [
        "def PYTORCH_reshape(X,new_shape):\n",
        "    \"\"\"\n",
        "    Reorganizes the tensor's elements to match a specified shape while maintaining the same number of elements.\n",
        "\n",
        "    Parameters:\n",
        "    x (torch.Tensor): 3-dimensional torch tensor.\n",
        "\n",
        "    new_shape (tuple): tuple with 3 elements which represents the new shape of the tensor.\n",
        "\n",
        "    Returns:\n",
        "    torch.Tensor: torch tensor of dimension 'new_shape'.\n",
        "    \"\"\"\n",
        "    return NotImplemented #TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19T3Ud8Im-gY"
      },
      "source": [
        "#### Test Example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CTBeU7bmm-gY"
      },
      "outputs": [],
      "source": [
        "np.random.seed(0)\n",
        "X = np.random.randint(0, 10, size=(3,10))\n",
        "\n",
        "X = numpy2tensor(X)\n",
        "\n",
        "\n",
        "\n",
        "print(PYTORCH_reshape(X,(2,3,5)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdvGcavRm-gY"
      },
      "source": [
        "**Expected Output**:\n",
        "<table style = \"align:40%\">\n",
        "    <tr>\n",
        "        <td style=\"text-align:left;\"><tt><b> PYTORCH_reshape(X,new_shape) </b></tt></td>\n",
        "        <td style=\"text-align:left;\"><tt>\n",
        "             [[[5,&nbsp;0,&nbsp;3,&nbsp;3,&nbsp;7&nbsp;], <br>\n",
        "        &nbsp; [9,&nbsp;3,&nbsp;5,&nbsp;2,&nbsp;4&nbsp;], <br>\n",
        "        &nbsp; [7,&nbsp;6,&nbsp;8,&nbsp;8,&nbsp;1&nbsp;]], <br>\n",
        "        <br>\n",
        "        &nbsp;[[6,&nbsp;7,&nbsp;7,&nbsp;8,&nbsp;1&nbsp;], <br>\n",
        "        &nbsp; [5,&nbsp;9,&nbsp;8,&nbsp;9,&nbsp;4&nbsp;], <br>\n",
        "        &nbsp; [3,&nbsp;0,&nbsp;3,&nbsp;5,&nbsp;0&nbsp;]]]\n",
        "        \n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d314jTpPm-gY"
      },
      "source": [
        "#### 3.5 Transpose\n",
        "\n",
        "In this task, you will implement the transpose function for torch tensors.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Your Task:** Implement the function `PYTORCH_transpose`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rGwokl5Hm-gY"
      },
      "outputs": [],
      "source": [
        "def PYTORCH_transpose(X,dim0,dim1):\n",
        "    \"\"\"\n",
        "    Reorganizes the tensor's elements and shape effectively by swapping along given direction.\n",
        "\n",
        "    Parameters:\n",
        "    x (torch.Tensor): 3-dimensional torch tensor.\n",
        "\n",
        "    dim0 (int): the first dimension to be transposed.\n",
        "\n",
        "    dim1 (int): the second dimension to be transposed.\n",
        "\n",
        "    Returns:\n",
        "    torch.Tensor: torch tensor of transposed version input.\n",
        "    \"\"\"\n",
        "    return NotImplemented #TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYLk7AHHm-gY"
      },
      "source": [
        "#### Test Example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0dQ_rDrbm-gY"
      },
      "outputs": [],
      "source": [
        "np.random.seed(0)\n",
        "X = np.random.randint(0, 10, size=(2,3,4))\n",
        "\n",
        "X = numpy2tensor(X)\n",
        "\n",
        "\n",
        "print(PYTORCH_transpose(X,1,2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxRUq3Tcm-gZ"
      },
      "source": [
        "**Expected Output**:\n",
        "<table style = \"align:40%\">\n",
        "    <tr>\n",
        "        <td style=\"text-align:left;\"><tt><b> PYTORCH_transpose(X,dim0,dim1) </b></tt></td>\n",
        "        <td style=\"text-align:left;\"><tt>\n",
        "             [[[5,&nbsp;7,&nbsp;2,], <br>\n",
        "        &nbsp; [0,&nbsp;9,&nbsp;4,], <br>\n",
        "        &nbsp; [3,&nbsp;3,&nbsp;7,], <br>\n",
        "        &nbsp; [3,&nbsp;5,&nbsp;6,]], <br>\n",
        "        <br>\n",
        "        &nbsp;[[8,&nbsp;7,&nbsp;5,], <br>\n",
        "        &nbsp; [8,&nbsp;7,&nbsp;9,], <br>\n",
        "        &nbsp; [1,&nbsp;8,&nbsp;8,], <br>\n",
        "        &nbsp; [6,&nbsp;1,&nbsp;9,]]] <br>\n",
        "        \n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ffbinT8m-gZ"
      },
      "source": [
        "#### 3.6 Permute\n",
        "\n",
        "In this task, you will implement the permute function for torch tensors.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Your Task:** Implement the function `PYTORCH_permute`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "StsE7aCWm-gZ"
      },
      "outputs": [],
      "source": [
        "def PYTORCH_permute(X,dims):\n",
        "    \"\"\"\n",
        "    Reorganizes the the dimensions of a tensor according to a specified permutation tuple while maintaining the data's order.\n",
        "\n",
        "    Parameters:\n",
        "    x (torch.Tensor): 3-dimensional torch tensor.\n",
        "\n",
        "    dims (tuple): tuple of integers that represents axis to be permuted\n",
        "\n",
        "    Returns:\n",
        "    torch.Tensor: torch tensor of permuted version input.\n",
        "    \"\"\"\n",
        "    return NotImplemented #TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlFXHKwem-gZ"
      },
      "source": [
        "#### Test Example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZnT8njwm-gZ"
      },
      "outputs": [],
      "source": [
        "np.random.seed(0)\n",
        "X = np.random.randint(0, 10, size=(2,3,4))\n",
        "\n",
        "X = numpy2tensor(X)\n",
        "\n",
        "\n",
        "print(PYTORCH_permute(X,(2,0,1)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdB3tN1dm-gZ"
      },
      "source": [
        "**Expected Output**:\n",
        "<table style = \"align:40%\">\n",
        "    <tr>\n",
        "        <td style=\"text-align:left;\"><tt><b> PYTORCH_permute(X,dims) </b></tt></td>\n",
        "        <td style=\"text-align:left;\"><tt>\n",
        "             [[[5,&nbsp;7,&nbsp;2,], <br>\n",
        "        &nbsp; [8,&nbsp;7,&nbsp;5,]], <br>\n",
        "        <br>\n",
        "        &nbsp;[[0,&nbsp;9,&nbsp;4,], <br>\n",
        "        &nbsp; [8,&nbsp;7,&nbsp;9,]], <br>\n",
        "        <br>\n",
        "        &nbsp;[[3,&nbsp;3,&nbsp;7,], <br>\n",
        "        &nbsp; [1,&nbsp;8,&nbsp;8,]], <br>\n",
        "        <br>\n",
        "        &nbsp;[[3,&nbsp;5,&nbsp;6,], <br>\n",
        "        &nbsp; [6,&nbsp;1,&nbsp;9,]]] <br>\n",
        "        \n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieeiAncym-gZ"
      },
      "source": [
        "#### 3.7 Concatenate\n",
        "\n",
        "In this task, you will implement the Concatenate function for torch tensors.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Your Task:** Implement the function `PYTORCH_concatenate`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3VHT1QZTm-gZ"
      },
      "outputs": [],
      "source": [
        "def PYTORCH_concatenate(tensors,dim):\n",
        "    \"\"\"\n",
        "    Reorganizes the the dimensions of a tensor according to a specified permutation tuple while maintaining the data's order.\n",
        "\n",
        "    Parameters:\n",
        "    tensors (tuple): tuple of Tensors with same shape except in concatenate dimension.\n",
        "\n",
        "    dim (int): concatenate dimension\n",
        "\n",
        "    Returns:\n",
        "    torch.Tensor: concatenated tensor.\n",
        "    \"\"\"\n",
        "    return NotImplemented #TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6b9JuLVim-gZ"
      },
      "source": [
        "#### Test Example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LEJXzoXRm-ga"
      },
      "outputs": [],
      "source": [
        "np.random.seed(0)\n",
        "X = np.random.randint(0, 10, size=(2,3,4))\n",
        "Y = np.random.randint(0, 3, size=(2,3,3))\n",
        "X = numpy2tensor(X)\n",
        "Y = numpy2tensor(Y)\n",
        "\n",
        "\n",
        "print(PYTORCH_concatenate((X,Y),2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nui-chnJm-ga"
      },
      "source": [
        "**Expected Output**:\n",
        "<table style = \"align:40%\">\n",
        "    <tr>\n",
        "        <td style=\"text-align:left;\"><tt><b> PYTORCH_concatenate(tensors,dim) </b></tt></td>\n",
        "        <td style=\"text-align:left;\"><tt>\n",
        "            [[[5,&nbsp;0,&nbsp;3,&nbsp;3,&nbsp;0,&nbsp;0,&nbsp;1], <br>\n",
        "            &nbsp; [7,&nbsp;9,&nbsp;3,&nbsp;5,&nbsp;2,&nbsp;0,&nbsp;2], <br>\n",
        "            &nbsp; [2,&nbsp;4,&nbsp;7,&nbsp;6,&nbsp;0,&nbsp;1,&nbsp;1]],<br>\n",
        "            <br>\n",
        "            &nbsp;[[8,&nbsp;8,&nbsp;1,&nbsp;6,&nbsp;2,&nbsp;0,&nbsp;1], <br>\n",
        "            &nbsp; [7,&nbsp;7,&nbsp;8,&nbsp;1,&nbsp;1,&nbsp;1,&nbsp;0], <br>\n",
        "            &nbsp; [5,&nbsp;9,&nbsp;8,&nbsp;9,&nbsp;2,&nbsp;0,&nbsp;2]]],<br>\n",
        "       \n",
        "        \n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAnK2um8m-ga"
      },
      "source": [
        "#### 3.8 Stack\n",
        "\n",
        "In this task, you will implement the stack function for torch tensors.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Your Task:** Implement the function `PYTORCH_stack`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOYp8Mr0m-ga"
      },
      "outputs": [],
      "source": [
        "def PYTORCH_stack(tensors,dim):\n",
        "\n",
        "    \"\"\"\n",
        "    In contrast to Concatenation, which merges two tensors along an existing dimension,\n",
        "    Stack creates a new dimension to combine tensors.\n",
        "\n",
        "    Parameters:\n",
        "    tensors (tuple):  tuple of tensors to be stacked\n",
        "    dim (int): dimension to insert.\n",
        "\n",
        "    Returns:\n",
        "    torch.Tensor: stacked tensor.\n",
        "    \"\"\"\n",
        "\n",
        "    return NotImplemented #TODO\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6Q152R9m-ga"
      },
      "source": [
        "#### Test Example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3hZe54j-m-ga"
      },
      "outputs": [],
      "source": [
        "np.random.seed(0)\n",
        "X = np.random.randint(0, 10, size=(2,3))\n",
        "Y = np.random.randint(0, 3, size=(2,3))\n",
        "X = numpy2tensor(X)\n",
        "Y = numpy2tensor(Y)\n",
        "\n",
        "\n",
        "print(PYTORCH_stack((X,Y),1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHG_DL7ym-ga"
      },
      "source": [
        "**Expected Output**:\n",
        "<table style = \"align:40%\">\n",
        "    <tr>\n",
        "        <td style=\"text-align:left;\"><tt><b> PYTORCH_stack(tensors,dims) </b></tt></td>\n",
        "        <td style=\"text-align:left;\"><tt>\n",
        "            [[[5,&nbsp;0,&nbsp;3,], <br>\n",
        "        &nbsp; [1,&nbsp;2,&nbsp;0,]], <br>\n",
        "        <br>\n",
        "        &nbsp;[[3,&nbsp;7,&nbsp;9,], <br>\n",
        "        &nbsp; [2,&nbsp;0,&nbsp;0,]]], <br>\n",
        "        <br>\n",
        "        \n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fexVGEz_m-ga"
      },
      "source": [
        "#### 3.9 Padding\n",
        "\n",
        "In this task, you will implement the padding  function for torch tensors.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Your Task:** Implement the function `PYTORCH_padding`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DAyLlSBom-ga"
      },
      "outputs": [],
      "source": [
        "def PYTORCH_padding(X,pad_widths):\n",
        "\n",
        "    \"\"\"\n",
        "    This involves adding extra elements (usually zeros) around the edges of a tensor.\n",
        "    We will encounter this during convolutional operations to control the spatial dimensions of the output.\n",
        "\n",
        "    Parameters:\n",
        "    X (torch.Tensor): input tensor which is to be padded.\n",
        "    pad_widths (tuple): even number of elements in tuple that represents padding widths in the order columns,rows and channels.\n",
        "\n",
        "    Returns:\n",
        "    torch.Tensor: stacked tensor.\n",
        "    \"\"\"\n",
        "\n",
        "    return NotImplemented #TODO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5AlNAnim-gb"
      },
      "outputs": [],
      "source": [
        "np.random.seed(0)\n",
        "X = np.random.randint(1, 10, size=(2,2,2))\n",
        "\n",
        "X = numpy2tensor(X)\n",
        "\n",
        "\n",
        "print(PYTORCH_padding(X,(2,2,1,1,0,0)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hna8R6vdm-gb"
      },
      "source": [
        "**Expected Output**:\n",
        "<table style = \"align:40%\">\n",
        "    <tr>\n",
        "        <td style=\"text-align:left;\"><tt><b> PYTORCH_padding(X,pad_widths) </b></tt></td>\n",
        "        <td style=\"text-align:left;\"><tt>\n",
        "     [[[0,&nbsp;0,&nbsp;0,&nbsp;0,&nbsp;0,&nbsp;0],<br>\n",
        "&nbsp; [0,&nbsp;0,&nbsp;6,&nbsp;1,&nbsp;0,&nbsp;0], <br>\n",
        "&nbsp; [0,&nbsp;0,&nbsp;4,&nbsp;4,&nbsp;0,&nbsp;0], <br>\n",
        "&nbsp; [0,&nbsp;0,&nbsp;0,&nbsp;0,&nbsp;0,&nbsp;0]] <br>\n",
        "<br>\n",
        "&nbsp;[[0,&nbsp;0,&nbsp;0,&nbsp;0,&nbsp;0,&nbsp;0], <br>\n",
        "&nbsp; [0,&nbsp;0,&nbsp;8,&nbsp;4,&nbsp;0,&nbsp;0], <br>\n",
        "&nbsp; [0,&nbsp;0,&nbsp;6,&nbsp;3,&nbsp;0,&nbsp;0], <br>\n",
        "&nbsp; [0,&nbsp;0,&nbsp;0,&nbsp;0,&nbsp;0,&nbsp;0]]]\n",
        "        </tt></td>\n",
        "    </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "CVR4lkxlQx2a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4. Build a Neural Network**\n",
        "\n",
        "Now we go through the basic concepts and functionalities of PyTorch to build a neural network. By the end of this notebook, you'll understand some basics on dataloaders/datasets, build simple neural networks, and train a model. You will also get context on how PyTorch runs computations on the CPU and GPU, and what CUDA is.\n"
      ],
      "metadata": {
        "id": "B76sGTAKRbzg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.1. Setting Up the Environment\n",
        "\n",
        "First, we need to install PyTorch. You can install it using pip. Run the following command in your terminal or in a code cell:"
      ],
      "metadata": {
        "id": "1gX1CJmOSwRd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "df8fPMfDTAMU",
        "outputId": "226b03de-029a-478d-dd0b-8f1f899f6680"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.2. Importing PyTorch\n",
        "\n",
        "Now, let's import necessary PyTorch libraries."
      ],
      "metadata": {
        "id": "ZQmljioHTR0X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "metadata": {
        "id": "iY_kpQ1CTqnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.2.1 CUDA\n",
        "\n",
        "When you train a neural network, PyTorch needs to know where to run the computations â€” either:\n",
        "\n",
        "1. On your CPU (default if no GPU is available), or\n",
        "\n",
        "2. On your GPU (which is much faster for deep learning, if available).\n",
        "\n",
        "Below is a standard way to check this in PyTorch. What this line does:\n",
        "\n",
        "- Checks if a CUDA-compatible GPU is available (i.e., an NVIDIA GPU). If it is, it sets device to \"cuda\", so your model/data will run on the GPU. This means you can achieve much faster training for large datasets (such as the ones you'll see in homeworks)\n",
        "- If you see device = \"cpu\", it means you're not connected to any GPUs - make sure they are selected in Google Collab / Kaggle / Active on your machine. If you use your CPU for training, it will be much slower for large models or datasets.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pppyvhXihIiQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0diQ98STTuSA",
        "outputId": "e4dc14d9-6802-4675-8015-2c8101e5c297"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.3. Building a Neural Network\n",
        "\n",
        "Now, let's build a simple neural network using PyTorch. We'll create a basic feedforward network to classify handwritten digits from the MNIST dataset. Once we have built our network, we must move it to our computational device so that PyTorch knows what resource to use for training."
      ],
      "metadata": {
        "id": "mES0vjJqTwG4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(SimpleNN, self).__init__()\n",
        "    self.fc1=nn.Linear(28*28, 128)\n",
        "    self.fc2=nn.Linear(128,64)\n",
        "    self.fc3=nn.Linear(64,10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x=x.view(-1, 28*28)\n",
        "    x=F.relu(self.fc1(x))\n",
        "    x=F.relu(self.fc2(x))\n",
        "    x=self.fc3(x)\n",
        "    return x\n",
        "\n",
        "net=SimpleNN().to(device)"
      ],
      "metadata": {
        "id": "RQJkH0GDT6Ui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.4. Loading the Dataset"
      ],
      "metadata": {
        "id": "m0DrXL1WUCff"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)\n",
        "\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "2rIn2H20URNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.5. Defining the Loss Function and Optimizer"
      ],
      "metadata": {
        "id": "9rFEVYOeTCU8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion=nn.CrossEntropyLoss()\n",
        "optimizer=optim.SGD(net.parameters(), lr=0.01, momentum=0.9)"
      ],
      "metadata": {
        "id": "0Q-6cXj0Ui4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.6. Training the network"
      ],
      "metadata": {
        "id": "z7SslhphUmgp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(5): #Loop over the dataset multiple time\n",
        "  running_loss=0.0\n",
        "  for i, data in enumerate(trainloader, 0):\n",
        "    inputs, lables=data\n",
        "    inputs, labels=inputs.to(device), lables.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    outputs=net(inputs)\n",
        "    loss=criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss +=loss.item()\n",
        "    if i%100 ==99: #print every 100 miini_batches\n",
        "      print(f'[Epoch {epoch+1}, Batch {i+1}] loss: {running_loss/100:.3f}')\n",
        "      running_loss=0.0\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "DytxDnj5UpvM",
        "outputId": "e551b177-744c-4b82-f15f-edf9fd0c0d74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 1, Batch 100] loss: 0.119\n",
            "[Epoch 1, Batch 200] loss: 0.103\n",
            "[Epoch 1, Batch 300] loss: 0.114\n",
            "[Epoch 1, Batch 400] loss: 0.128\n",
            "[Epoch 1, Batch 500] loss: 0.105\n",
            "[Epoch 1, Batch 600] loss: 0.126\n",
            "[Epoch 1, Batch 700] loss: 0.118\n",
            "[Epoch 1, Batch 800] loss: 0.118\n",
            "[Epoch 1, Batch 900] loss: 0.125\n",
            "[Epoch 1, Batch 1000] loss: 0.093\n",
            "[Epoch 1, Batch 1100] loss: 0.107\n",
            "[Epoch 1, Batch 1200] loss: 0.117\n",
            "[Epoch 1, Batch 1300] loss: 0.109\n",
            "[Epoch 1, Batch 1400] loss: 0.109\n",
            "[Epoch 1, Batch 1500] loss: 0.140\n",
            "[Epoch 1, Batch 1600] loss: 0.115\n",
            "[Epoch 1, Batch 1700] loss: 0.134\n",
            "[Epoch 1, Batch 1800] loss: 0.113\n",
            "[Epoch 2, Batch 100] loss: 0.096\n",
            "[Epoch 2, Batch 200] loss: 0.103\n",
            "[Epoch 2, Batch 300] loss: 0.093\n",
            "[Epoch 2, Batch 400] loss: 0.091\n",
            "[Epoch 2, Batch 500] loss: 0.105\n",
            "[Epoch 2, Batch 600] loss: 0.096\n",
            "[Epoch 2, Batch 700] loss: 0.096\n",
            "[Epoch 2, Batch 800] loss: 0.101\n",
            "[Epoch 2, Batch 900] loss: 0.100\n",
            "[Epoch 2, Batch 1000] loss: 0.083\n",
            "[Epoch 2, Batch 1100] loss: 0.111\n",
            "[Epoch 2, Batch 1200] loss: 0.097\n",
            "[Epoch 2, Batch 1300] loss: 0.082\n",
            "[Epoch 2, Batch 1400] loss: 0.090\n",
            "[Epoch 2, Batch 1500] loss: 0.087\n",
            "[Epoch 2, Batch 1600] loss: 0.113\n",
            "[Epoch 2, Batch 1700] loss: 0.075\n",
            "[Epoch 2, Batch 1800] loss: 0.101\n",
            "[Epoch 3, Batch 100] loss: 0.070\n",
            "[Epoch 3, Batch 200] loss: 0.078\n",
            "[Epoch 3, Batch 300] loss: 0.074\n",
            "[Epoch 3, Batch 400] loss: 0.075\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-38-584931234.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#Loop over the dataset multiple time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mrunning_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \"\"\"\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_float_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEY8tRn7Uu97",
        "outputId": "31f99b9f-73d1-4cb0-ba48-c0f30323f829"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 96.86%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.6. Conclusion\n",
        "\n",
        "Bravo! Just now, using PyTorch, you constructed and trained a basic neural network. We discussed:\n",
        "\n",
        "\n",
        "Build and work with tensors\n",
        "\n",
        "Constructing a neural network\n",
        "\n",
        "Testing and educating the network\n",
        "\n",
        "Try changing the training parameters and network architecture to observe how it affects performance. Cheers to learning!"
      ],
      "metadata": {
        "id": "5NN6vUzQU04u"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "cve",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
